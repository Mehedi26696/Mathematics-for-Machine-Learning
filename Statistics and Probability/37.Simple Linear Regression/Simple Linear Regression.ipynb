{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82adc755-982b-4e1b-9d24-8615c80364ec",
   "metadata": {},
   "source": [
    "# Simple Linear Regression\n",
    "\n",
    "Simple linear regression is a fundamental statistical method used to model the relationship between a single dependent variable and one independent variable. It aims to find the best-fitting straight line through the data points, which can be used to predict the dependent variable based on the independent variable.\n",
    "\n",
    "## The Simple Linear Regression Model\n",
    "\n",
    "The mathematical representation of the simple linear regression model is:\n",
    "\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i, \\quad i = 1, 2, \\dots, n\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $y_i$ is the $i $-th observation of the dependent variable.\n",
    "- $x_i$ is the $i $-th observation of the independent variable.\n",
    "- $\\beta_0$ is the intercept (the expected value of $y$ when $x = 0$).\n",
    "- $\\beta_1$ is the slope (the average change in $y$ for a one-unit change in $x$).\n",
    "- $\\varepsilon_i$ is the error term, assumed to be independently and identically distributed with mean zero and constant variance $\\sigma^2 $.\n",
    "\n",
    "### Assumptions of the Model\n",
    "\n",
    "For the simple linear regression model to be valid, several key assumptions must be met:\n",
    "\n",
    "1. **Linearity** indicates that the relationship between $x$ and $y$ is linear.\n",
    "2. **Independence** means the residuals (errors) $\\varepsilon_i$ are independent of one another.\n",
    "3. **Homoscedasticity** suggests that the residuals have a constant variance ($\\sigma^2$) across all values of $x$.\n",
    "4. **Normality** assumes that the residuals follow a normal distribution.\n",
    "5. Finally, **no measurement error in $x** ensures that the independent variable $x$ is measured without error.\n",
    "\n",
    "## Estimation of Coefficients Using the Least Squares Method\n",
    "\n",
    "The goal is to find estimates $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ that minimize the sum of squared residuals (differences between observed and predicted values):\n",
    "\n",
    "$$\n",
    "\\text{SSE} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{n} (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)^2\n",
    "$$\n",
    "\n",
    "### Calculating the Slope ($\\hat{\\beta}_1$) and Intercept ($\\hat{\\beta}_0$)\n",
    "\n",
    "The least squares estimates are calculated using the following formulas:\n",
    "\n",
    "#### Slope ($\\hat{\\beta}_1$)\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} = \\frac{\\text{Cov}(x, y)}{\\text{Var}(x)}\n",
    "$$\n",
    "\n",
    "#### Intercept ($\\hat{\\beta}_0$)\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\bar{x} = \\dfrac{1}{n} \\sum_{i=1}^{n} x_i$ is the mean of the independent variable.\n",
    "- $\\bar{y} = \\dfrac{1}{n} \\sum_{i=1}^{n} y_i$ is the mean of the dependent variable.\n",
    "\n",
    "## Interpretation of the Coefficients\n",
    "\n",
    "- The **intercept ($\\hat{\\beta}_0$)** represents the expected value of $y$ when $x = 0$, marking the point where the regression line intersects the $y$-axis.\n",
    "- The **slope ($\\hat{\\beta}_1$)** indicates the average change in $y$ for each one-unit increase in $x$.\n",
    "\n",
    "## Assessing the Fit of the Model\n",
    "\n",
    "### Total Sum of Squares (SST)\n",
    "\n",
    "Measures the total variability in the dependent variable:\n",
    "\n",
    "$$\n",
    "\\text{SST} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2\n",
    "$$\n",
    "\n",
    "### Regression Sum of Squares (SSR)\n",
    "\n",
    "Measures the variability explained by the regression:\n",
    "\n",
    "$$\n",
    "\\text{SSR} = \\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2\n",
    "$$\n",
    "\n",
    "### Sum of Squared Errors (SSE)\n",
    "\n",
    "Measures the unexplained variability:\n",
    "\n",
    "$$\n",
    "\\text{SSE} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "### Coefficient of Determination ($R^2 $)\n",
    "\n",
    "Indicates the proportion of variance in $y$ explained by $x$:\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\text{SSR}}{\\text{SST}} = 1 - \\frac{\\text{SSE}}{\\text{SST}}\n",
    "$$\n",
    "\n",
    "An $R^2 $ value close to 1 suggests a strong linear relationship.\n",
    "\n",
    "## Hypothesis Testing\n",
    "\n",
    "### Testing the Significance of the Slope\n",
    "\n",
    "- **Null Hypothesis ($H_0$)**: $\\beta_1 = 0$ (no linear relationship)\n",
    "- **Alternative Hypothesis ($H_a $)**: $\\beta_1 \\neq 0$\n",
    "\n",
    "**Test Statistic**:\n",
    "\n",
    "$$\n",
    "t = \\frac{\\hat{\\beta}_1}{\\text{SE}(\\hat{\\beta}_1)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "\\text{SE}(\\hat{\\beta}_1) = \\frac{s}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}}\n",
    "$$\n",
    "\n",
    "And:\n",
    "\n",
    "$$\n",
    "s = \\sqrt{\\frac{\\text{SSE}}{n - 2}}\n",
    "$$\n",
    "\n",
    "The test statistic follows a $t $-distribution with $n - 2 $ degrees of freedom.\n",
    "\n",
    "## Example\n",
    "\n",
    "Suppose we have the following data on the number of hours studied ($x$) and the test scores ($y$):\n",
    "\n",
    "| Hours Studied ($x$) | Test Score ($y$) |\n",
    "|-------------------------|-----------------------|\n",
    "| 2                       | 50                    |\n",
    "| 4                       | 60                    |\n",
    "| 6                       | 70                    |\n",
    "| 8                       | 80                    |\n",
    "\n",
    "### Step-by-Step Calculation\n",
    "\n",
    "#### 1. Calculate the Means\n",
    "\n",
    "$$\n",
    "\\bar{x} = \\frac{2 + 4 + 6 + 8}{4} = 5\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\bar{y} = \\frac{50 + 60 + 70 + 80}{4} = 65\n",
    "$$\n",
    "\n",
    "#### 2. Compute the Sum of Squares and Cross-Products\n",
    "\n",
    "Create a table to organize calculations:\n",
    "\n",
    "| $x_i$ | $y_i$ | $x_i - \\bar{x} $ | $y_i - \\bar{y} $ | $(x_i - \\bar{x})(y_i - \\bar{y})$ | $(x_i - \\bar{x})^2 $ |\n",
    "|-----------|-----------|---------------------|---------------------|--------------------------------------|-------------------------|\n",
    "| 2         | 50        | -3                  | -15                 | 45                                   | 9                       |\n",
    "| 4         | 60        | -1                  | -5                  | 5                                    | 1                       |\n",
    "| 6         | 70        | 1                   | 5                   | 5                                    | 1                       |\n",
    "| 8         | 80        | 3                   | 15                  | 45                                   | 9                       |\n",
    "| **Total** |           |                     |                     | **100**                               | **20**                  |\n",
    "\n",
    "**Sum of Cross-Products**:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y}) = 100\n",
    "$$\n",
    "\n",
    "**Sum of Squares of $x$**:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} (x_i - \\bar{x})^2 = 20\n",
    "$$\n",
    "\n",
    "#### 3. Calculate the Slope ($\\hat{\\beta}_1$)\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_1 = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2} = \\frac{100}{20} = 5\n",
    "$$\n",
    "\n",
    "#### 4. Calculate the Intercept ($\\hat{\\beta}_0$)\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x} = 65 - (5)(5) = 40\n",
    "$$\n",
    "\n",
    "#### 5. Formulate the Regression Equation\n",
    "\n",
    "$$\n",
    "\\hat{y} = 40 + 5x\n",
    "$$\n",
    "\n",
    "#### 6. Predict the Test Scores and Calculate Residuals\n",
    "\n",
    "| $x_i$ | $y_i$ | $\\hat{y}_i = 40 + 5x_i$ | Residuals ($y_i - \\hat{y}_i$) |\n",
    "|-----------|-----------|------------------------------|-----------------------------------|\n",
    "| 2         | 50        | 50                           | 0                                 |\n",
    "| 4         | 60        | 60                           | 0                                 |\n",
    "| 6         | 70        | 70                           | 0                                 |\n",
    "| 8         | 80        | 80                           | 0                                 |\n",
    "\n",
    "#### 7. Calculate the Sum of Squares\n",
    "\n",
    "**Total Sum of Squares (SST)**:\n",
    "\n",
    "$$\n",
    "\\text{SST} = \\sum (y_i - \\bar{y})^2 = (-15)^2 + (-5)^2 + 5^2 + 15^2 = 500\n",
    "$$\n",
    "\n",
    "**Sum of Squared Errors (SSE)**:\n",
    "\n",
    "$$\n",
    "\\text{SSE} = \\sum (y_i - \\hat{y}_i)^2 = 0\n",
    "$$\n",
    "\n",
    "**Regression Sum of Squares (SSR)**:\n",
    "\n",
    "$$\n",
    "\\text{SSR} = \\text{SST} - \\text{SSE} = 500 - 0 = 500\n",
    "$$\n",
    "\n",
    "#### 8. Compute the Coefficient of Determination ($R^2 $)\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\text{SSR}}{\\text{SST}} = \\frac{500}{500} = 1\n",
    "$$\n",
    "\n",
    "An $R^2 $ value of 1 indicates that the model perfectly explains the variability in the test scores.\n",
    "\n",
    "<img src=\"sl1.png\">\n",
    "\n",
    "#### 9. Calculate the Standard Error of the Estimate ($s $)\n",
    "\n",
    "$$\n",
    "s = \\sqrt{\\frac{\\text{SSE}}{n - 2}} = \\sqrt{\\frac{0}{2}} = 0\n",
    "$$\n",
    "\n",
    "Since $s = 0$, the standard errors of the coefficients are zero, which is a result of the perfect fit.\n",
    "\n",
    "#### 10. Hypothesis Testing (Optional)\n",
    "\n",
    "In this case, the test statistic for $\\hat{\\beta}_1$ is undefined due to division by zero in the standard error. However, in practice, with more realistic data where $s > 0$, you would perform a $t $-test to assess the significance of the slope.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
