{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b361484b-5403-4147-8f71-d65b9555c9a5",
   "metadata": {},
   "source": [
    "## ANOVA and the Analysis of Variance for Multiple Groups\n",
    "\n",
    "### Scenario: Peer Assessment and Student Learning\n",
    "\n",
    "**Does peer assessment enhance student learning?**\n",
    "\n",
    "- A study **investigated** whether different instructional methods lead to varying learning outcomes, measured by final exam scores.\n",
    "- Students were **randomly assigned** to one of three treatment groups to analyze performance.\n",
    "- One group **completed homework** assignments independently, without any peer assessment.\n",
    "- Another group completed homework and **participated** in peer assessment, where students evaluated each other’s work.\n",
    "- A third group **studied independently** without doing homework.\n",
    "- Final exam scores for students in each group were **collected** for comparison.\n",
    "- The final exam scores were **summarized** and visualized using boxplots.\n",
    "- The main objective of the study was to determine if different **instructional methods** significantly affected learning outcomes, as reflected in final exam results.\n",
    "\n",
    "#### Formulating the Hypotheses\n",
    "\n",
    "To statistically assess the impact of the different treatments, we set up the following hypotheses:\n",
    "\n",
    "I. **Null Hypothesis ($H_0$)**: All group means are equal. That is, there is no significant difference in final exam scores between the three treatment groups.\n",
    "  \n",
    "$$\n",
    "H_0: \\mu_1 = \\mu_2 = \\mu_3\n",
    "$$\n",
    "\n",
    "II. **Alternative Hypothesis ($H_A$)**: At least one group mean is different, indicating that the treatments have different effects on student learning.\n",
    "\n",
    "$$\n",
    "H_A: \\text{At least one } \\mu_j \\text{ differs}\n",
    "$$\n",
    "\n",
    "#### Comparing Two Groups: The Two-Sample t-Test\n",
    "\n",
    "When comparing only two groups, the **two-sample t-test** is appropriate. It tests whether there is a significant difference between the means of two independent groups.\n",
    "\n",
    "I. **t-Test Formula**\n",
    "\n",
    "The t-statistic is calculated as:\n",
    "\n",
    "$$\n",
    "t = \\frac{y_1 - y_2}{SE_{y_1 - y_2}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\bar{y}_1, \\bar{y}_2$: Sample means of groups 1 and 2.\n",
    "- $SE_{\\bar{y}_1 - \\bar{y}_2}$: Standard error of the difference between the two sample means.\n",
    "\n",
    "II. **Standard Error Calculation**\n",
    "\n",
    "Assuming equal variances:\n",
    "\n",
    "$$\n",
    "SE_{\\bar{y}_1 - \\bar{y}_2} = \\sqrt{\\frac{s^2}{n_1} + \\frac{s^2}{n_2}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $s^2$: Pooled sample variance.\n",
    "- $n_1, n_2$: Sample sizes of groups 1 and 2.\n",
    "\n",
    "III. **Limitations**\n",
    "\n",
    "- The t-test is limited to comparing **two** groups.\n",
    "- When dealing with more than two groups, the risk of Type I error increases with multiple t-tests.\n",
    "\n",
    "### ANOVA: Analysis of Variance for Multiple Groups\n",
    "\n",
    "To compare **three or more groups**, we use **Analysis of Variance (ANOVA)**. ANOVA tests for significant differences among group means by analyzing variances.\n",
    "\n",
    "Key Concepts:\n",
    "\n",
    "- **Between-groups variance** refers to the variability caused by the interaction between different treatment groups.\n",
    "- **Within-groups variance** refers to the variability within each group that arises from individual differences.\n",
    "\n",
    "ANOVA Hypotheses:\n",
    "\n",
    "- The **null hypothesis (H₀)** in ANOVA states that all group means are equal.\n",
    "- The **alternative hypothesis (Hₐ)** suggests that not all group means are equal.\n",
    "\n",
    "#### The ANOVA Methodology\n",
    "\n",
    "ANOVA partitions the total variability in the data into components attributable to various sources.\n",
    "\n",
    "### Total Sum of Squares (SSTotal)\n",
    "\n",
    "The **Total Sum of Squares** measures the total variability in the data:\n",
    "\n",
    "$$\n",
    "SSTotal = \\sum_{i=1}^{N} (y_i - \\bar{y})^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $y_i$: Individual observations.\n",
    "- $\\bar{y}$: Overall mean of all observations.\n",
    "- $N$: Total number of observations.\n",
    "\n",
    "#### 1. Treatment Variance (Between-Groups Variability)\n",
    "\n",
    "**Sum of Squares for Treatments (SST)** measures the variability between the group means and the overall mean:\n",
    "\n",
    "$$\n",
    "SST = \\sum_{j=1}^{k} n_j (\\bar{y}_j - \\bar{y})^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $n_j$: Sample size of group $j$.\n",
    "- $\\bar{y}_j$: Mean of group $j$.\n",
    "- $k$: Number of groups.\n",
    "\n",
    "**Treatment Mean Square (MST)** is the average treatment variability:\n",
    "\n",
    "$$\n",
    "MST = \\frac{SST}{k - 1}\n",
    "$$\n",
    "\n",
    "Degrees of freedom for treatments: $df_{\\text{Treatment}} = k - 1$.\n",
    "\n",
    "#### 2. Error Variance (Within-Groups Variability)\n",
    "\n",
    "**Sum of Squares for Error (SSE)** measures the variability within the groups:\n",
    "\n",
    "$$\n",
    "SSE = \\sum_{j=1}^{k} \\sum_{i=1}^{n_j} (y_{ij} - \\bar{y}_j)^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $y_{ij}$: Individual observation in group $j$.\n",
    "- $\\bar{y}_j$: Mean of group $j$.\n",
    "\n",
    "**Error Mean Square (MSE)** is the average within-group variability:\n",
    "\n",
    "$$\n",
    "MSE = \\frac{SSE}{N - k}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- Degrees of freedom for error: $df_{\\text{Error}} = N - k$.\n",
    "\n",
    "#### 3. Calculating the F-Statistic\n",
    "\n",
    "The **F-statistic** compares the between-groups variance to the within-groups variance:\n",
    "\n",
    "$$\n",
    "F = \\frac{MST}{MSE}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- Under $H_0$, $MST$ and $MSE$ estimate the same variance, so $F \\approx 1$.\n",
    "- A large $F$ value suggests that between-group variability is greater than within-group variability, indicating significant differences among group means.\n",
    "\n",
    "**F-Distribution**\n",
    "\n",
    "- The F-statistic follows an F-distribution with $df_1 = k - 1$ (numerator degrees of freedom) and $df_2 = N - k$ (denominator degrees of freedom).\n",
    "- The p-value is determined based on the F-distribution.\n",
    "\n",
    "### Example: Peer Assessment Data\n",
    "\n",
    "#### Data Summary\n",
    "\n",
    "Suppose we have the following data:\n",
    "\n",
    "- The **group sizes** are defined as: Homework Only ($n_1$), Homework with Peer Assessment ($n_2$), and Study Without Homework ($n_3$).\n",
    "- The **group means** ($\\bar{y}_j$) and **variances** ($s_j^2$) are calculated based on the collected data.\n",
    "- The **total number of observations** is represented as $N = n_1 + n_2 + n_3$.\n",
    "\n",
    "#### ANOVA Table Construction\n",
    "\n",
    "**ANOVA Table** summarizes the calculations:\n",
    "\n",
    "| Source      | df            | Sum of Squares (SS) | Mean Square (MS)      | F       |\n",
    "|-------------|---------------|---------------------|-----------------------|---------|\n",
    "| Treatment   | $k - 1$   | SST                 | $MST = \\frac{SST}{k - 1}$ | $F = \\frac{MST}{MSE}$ |\n",
    "| Error       | $N - k$   | SSE                 | $MSE = \\frac{SSE}{N - k}$ |         |\n",
    "| Total       | $N - 1$   | SSTotal             |                       |         |\n",
    "\n",
    "**Given Example**:\n",
    "\n",
    "| Source      | df  | Sum of Squares | Mean Square | F     |\n",
    "|-------------|-----|----------------|-------------|-------|\n",
    "| Treatment   | 2   | 98.4           | 49.2        | 2.57  |\n",
    "| Error       | 38  | 723.8          | 19.05       |       |\n",
    "| Total       | 40  | 822.2          |             |       |\n",
    "\n",
    "#### Calculations\n",
    "\n",
    "**SSTotal**:\n",
    "\n",
    "$$\n",
    "SSTotal = SST + SSE = 98.4 + 723.8 = 822.2\n",
    "$$\n",
    "\n",
    "**Degrees of Freedom**:\n",
    "\n",
    "- $df_{\\text{Treatment}} = k - 1 = 3 - 1 = 2$\n",
    "- $df_{\\text{Error}} = N - k = 41 - 3 = 38$\n",
    "- $df_{\\text{Total}} = N - 1 = 41 - 1 = 40$\n",
    "\n",
    "**Mean Squares**:\n",
    "\n",
    "- $MST = \\frac{SST}{df_{\\text{Treatment}}} = \\frac{98.4}{2} = 49.2$\n",
    "- $MSE = \\frac{SSE}{df_{\\text{Error}}} = \\frac{723.8}{38} \\approx 19.05$\n",
    "\n",
    "**F-Statistic**:\n",
    "\n",
    "$$\n",
    "F = \\frac{MST}{MSE} = \\frac{49.2}{19.05} \\approx 2.58\n",
    "$$\n",
    "\n",
    "**P-Value**:\n",
    "\n",
    "- Using F-distribution tables or software, with $df_1 = 2$ and $df_2 = 38$, we find:\n",
    "- **p-value** ≈ 0.087\n",
    "\n",
    "#### Decision\n",
    "\n",
    "- At a significance level of **$\\alpha = 0.05$**, since **$p = 0.087 > 0.05$**, we **fail to reject $H_0$**.\n",
    "- There is not enough evidence to conclude that the **treatments** have different effects on student learning.\n",
    "\n",
    "### Interpretation of ANOVA Results\n",
    "\n",
    "#### Understanding the F-Statistic\n",
    "\n",
    "- A **small F-value** (around 1) suggests that the variability between group means is similar to the variability within groups, implying **no significant difference** among group means.\n",
    "- A **large F-value** indicates that the variability between group means is greater than the variability within groups, suggesting **significant differences** among group means.\n",
    "\n",
    "#### P-Value Interpretation\n",
    "\n",
    "- If the **p-value is less than $\\alpha$**, we reject **$H_0$** and conclude that at least one group mean is different.\n",
    "- If the **p-value is greater than or equal to $\\alpha$**, we fail to reject **$H_0$** and cannot conclude that there are differences among group means.\n",
    "\n",
    "#### Conclusion for the Example\n",
    "\n",
    "- With a **p-value of 0.087**, there is not sufficient evidence at the 5% significance level to claim that peer assessment improves student learning over other methods.\n",
    "- However, the **p-value is close** to 0.05, suggesting a potential trend that might reach significance with a larger sample size.\n",
    "\n",
    "### The One-Way ANOVA Model\n",
    "\n",
    "#### Statistical Model\n",
    "\n",
    "The **one-way ANOVA model** expresses each observation as:\n",
    "\n",
    "$$\n",
    "y_{ij} = \\mu_j + \\epsilon_{ij}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $y_{ij}$: Observation $i$ in group $j$.\n",
    "- $\\mu_j$: Mean of group $j$.\n",
    "- $\\epsilon_{ij}$: Random error term, assumed to be independently and identically distributed (i.i.d.) with:\n",
    "  - Mean $E[\\epsilon_{ij}] = 0$\n",
    "  - Variance $Var(\\epsilon_{ij}) = \\sigma^2$\n",
    "\n",
    "#### Alternative Representation\n",
    "\n",
    "We can express the model in terms of the overall mean $\\mu$ and group effects $\\tau_j$:\n",
    "\n",
    "$$\n",
    "y_{ij} = \\mu + \\tau_j + \\epsilon_{ij}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\mu$: Overall mean.\n",
    "- $\\tau_j = \\mu_j - \\mu$: Effect of treatment $j$.\n",
    "\n",
    "#### Assumptions of the Model\n",
    "\n",
    "1. **Normality**: The residuals $\\epsilon_{ij}$ are normally distributed.\n",
    "2. **Independence**: Observations are independent.\n",
    "3. **Homogeneity of Variance**: The variances within each group are equal ($\\sigma^2$ is constant across groups).\n",
    "\n",
    "### Assumptions of the F-Test\n",
    "\n",
    "For the results of the ANOVA F-test to be valid, certain assumptions must be met:\n",
    "\n",
    "#### 1. Equal Variances (Homogeneity of Variance)\n",
    "\n",
    "- The **assumption** is that the variances within each group are equal.\n",
    "- This can be **checked** using boxplots for visual inspection of similar spread among groups.\n",
    "- **Levene's Test** can be used as a statistical method to test for equal variances.\n",
    "- A **rule of thumb** states that if the largest sample standard deviation is no more than twice the smallest, the assumption is reasonable.\n",
    "\n",
    "#### 2. Independence of Observations\n",
    "\n",
    "- The **assumption** is that observations are independent both within and across groups.\n",
    "- This is **ensured** by random assignment in experimental studies or random sampling in observational studies.\n",
    "\n",
    "#### 3. Normality of Residuals\n",
    "\n",
    "- The **assumption** is that the residuals ($\\epsilon_{ij}$) are normally distributed.\n",
    "- This can be **checked** by using normal probability plots to assess the normality of residuals.\n",
    "- The **Shapiro-Wilk Test** is a formal statistical test for normality.\n",
    "\n",
    "### Post-ANOVA Testing\n",
    "\n",
    "If the ANOVA F-test leads us to reject $H_0$, indicating that not all group means are equal, we may want to identify **which groups differ**.\n",
    "\n",
    "Performing multiple t-tests increases the risk of Type I error (false positives). To control for this, we use:\n",
    "\n",
    "#### 1. Bonferroni Correction\n",
    "\n",
    "Adjusts the significance level:\n",
    "  \n",
    "$$\n",
    "\\alpha' = \\frac{\\alpha}{\\text{Number of Comparisons}}\n",
    "$$\n",
    "  \n",
    "Example: For 3 groups, there are $\\frac{3 \\times 2}{2} = 3$ comparisons.\n",
    "\n",
    "#### 2. Tukey's Honest Significant Difference (HSD) Test\n",
    "\n",
    "- Controls the family-wise error rate.\n",
    "- Computes confidence intervals for all pairwise differences.\n",
    "\n",
    "#### Steps for Pairwise Comparisons\n",
    "\n",
    "I. **Calculate the Standard Error for Differences**:\n",
    "\n",
    "$$\n",
    "SE_{\\bar{y}_i - \\bar{y}_j} = \\sqrt{MSE \\left( \\frac{1}{n_i} + \\frac{1}{n_j} \\right)}\n",
    "$$\n",
    "\n",
    "II. **Compute the t-Statistic for Each Pair**:\n",
    "\n",
    "$$\n",
    "t = \\frac{y_i - y_j}{SE_{y_i - y_j}}\n",
    "$$\n",
    "\n",
    "III. **Determine the Adjusted p-Values**:\n",
    "\n",
    "Use the adjusted significance level or critical values from Tukey's distribution.\n",
    "\n",
    "### Practical Application Steps\n",
    "\n",
    "#### 1. Conduct ANOVA\n",
    "\n",
    "- Compute SST, SSE, MST, MSE, and F-statistic.\n",
    "- Determine the p-value using the F-distribution.\n",
    "- Decide whether to reject $H_0$ based on the p-value.\n",
    "\n",
    "#### 2. Check Assumptions\n",
    "\n",
    "- To check for **equal variances**, use boxplots or formal statistical tests.\n",
    "- **Normality** is assessed by examining the residuals.\n",
    "- Ensure that the study design supports **independence** of observations.\n",
    "\n",
    "#### 3. Interpret Results\n",
    "\n",
    "- If **$H_0$ is not rejected**, conclude that there is no significant difference among group means.\n",
    "- If **$H_0$ is rejected**, proceed to post-hoc tests to identify specific group differences.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
